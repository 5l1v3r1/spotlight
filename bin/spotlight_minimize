#! /usr/bin/env python
""" Optimizes a refinement plan.
"""

import argparse
import numpy
import os
import socket
import time
from mpi4py import MPI
from mystic import termination
from mystic import tools
from spotlight import diffraction
from spotlight import solver
from spotlight.io import solution_file
from spotlight.io import state_file

# parse command line
parser = argparse.ArgumentParser(description=__doc__)
parser.add_argument("--config-files", nargs="+", required=True)
parser.add_argument("--config-overrides", nargs="+")
parser.add_argument("--data-file", required=True)
parser.add_argument("--refinement-plan-file", required=True)
parser.add_argument("--output-file", default="solution.pkl")
parser.add_argument("--state-file", default="state.pkl")
parser.add_argument("--tmp-dir", default="tmp")
parser.add_argument("--seed", type=int, default=0)
parser.add_argument("--num-solvers", type=int, default=1)
parser.add_argument("--tag", default=None)
parser.add_argument("--verbose", action="store_true")
opts = parser.parse_args()

# get parallel-processing information
hostname = socket.gethostname()
run_dir = os.getcwd()
comm = MPI.COMM_WORLD
size = comm.Get_size()
rank = comm.Get_rank()

# wait a bit because the klepto file seems to drop some initial results
# we hope later its not an issue
time.sleep(rank)

# set random seed
seed = rank + opts.seed
numpy.random.seed(seed)
tools.random_seed(seed)

# move to temporary dir, read configuration file, and get refinement plan
tmp_dir = "{}_{}".format(opts.tmp_dir, rank)
diff = diffraction.Diffraction(opts.config_files, opts.refinement_plan_file,
                               opts.data_file, tmp_dir, change=True,
                               config_overrides=opts.config_overrides)
cost = diff.get_refinement_plan()

# create a cached archive file for output data
output_file = opts.output_file if opts.output_file.startswith("/") \
                  else run_dir + "/" + opts.output_file
fp_sol = solution_file.SolutionFile(output_file, diff.names)

# create a cached archive file for state data
output_file = opts.state_file if opts.state_file.startswith("/") \
                  else run_dir + "/" + opts.state_file
fp_state = state_file.StateFile(output_file)

# run one of ensemble of solvers
for i in range(opts.num_solvers):
    local_tag = (rank, i, opts.tag)

    # check if there is a previous state for a local solver
    fp_sol.arch.load(local_tag)
    if local_tag in fp_sol.arch.keys():

        # if the local solver has not terminated then start from there
        # we have to explicltly set the termination conditions because Mystic
        # parses ``__doc__`` for getting the conditions YIKES!
        fp_state.arch.load(local_tag)
        if fp_sol.arch[local_tag][4] == False and local_tag in fp_state.arch.keys():
            print "Loading a previous state for", local_tag
            local_solver = fp_state.arch[local_tag]
            local_solver.local_solver.SetEvaluationLimits(
                local_solver.max_iterations,
                local_solver.max_evaluations)
            local_solver.stop = termination.NormalizedChangeOverGeneration(
                local_solver.stop_change, local_solver.stop_generations)

        # otherwise initialize a local solver from configuration file
        else:
            print "Optimization loop already terminated for", local_tag
            continue

    # if there is not a previous state initialize local solver
    else:
        print "Initializing a state for", local_tag
        local_solver = solver.Solver(diff.lower_bounds, diff.upper_bounds,
                                     diff.config_file, arch=fp_sol, iteration=i)

    # print statement
    print "Process", rank + 1, "of", size, \
          "running walker", i + 1, "of", opts.num_solvers, "on", hostname

    # set timer
    t1 = time.time()

    # main optimization loop with checkpointing
    if local_solver.checkpoint_stride:
        stop = False
        while not stop:
    
            # take steps in optimization
            for _ in range(local_solver.checkpoint_stride):
                stop = local_solver.step(cost)
    
            # save output
            fp_sol.save_data(local_tag, local_solver)
            fp_state.save_state(local_tag, local_solver)

    # main optimization loop without checkpointing
    else:
        local_solver.solve(cost)
        fp_sol.save_data(local_tag, local_solver)
        fp_state.save_state(local_tag, local_solver)

    # print statement
    print "Evaluation time for process", rank, "of", size, \
          "running walker", i + 1, "of", opts.num_solvers, "on", hostname, \
          "is", time.time() - t1, "s"
